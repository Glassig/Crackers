\section{The Game}
The game is inspired by the previously mentioned Zork. It consists of a few rooms and tasks to be performed before reaching a victory scenario. The game differs in environments and plot between the different implementations of NLIs, which requires the user to input different commands in order to win. One version uses typing to control your character’s actions and the other uses speech. The reason we decided to create two implementations is so that a user who has played one control-scheme could still play the other without having the benefit of knowing what is required to win.

\subsection{Plot}
You play as a bunny that has escaped its cage and is on the hunt for food. You need to eat three crackers in each game in order to ease your hunger and win the game. In the speech version you are a house-pet and are in an apartment and has the ability to be in the kitchen, the livingroom and the bedroom. In the text version you are a class-pet in a school and can visit the classroom, the hallway and the cafeteria.

\section{Evaluation}
“[...] the usability of any tool or system has to be viewed in terms of the context in which it is used, and its appropriateness to that context” (John Brooks, 1996). In 1986 John Brooks created a way to test a user interface and its usability. The idea is that a user tries out a system after which they answer a specific questionnaire, developed by Brooks, concerning the usability of the system. The user should not think for a long period of time or discuss their opinion with anyone before or while filling out the questionnaire. It is important that the user’s initial thought and own experience is recorded.

The questionnaire consists of 10 statements and the user must rank each statement by a scale of 1-5, where 1 is “strongly disagree” and 5 is “strongly agree”. Some examples of the statements are “I thought the system was easy to use” and “I thought there was too much inconsistency in this system”. All the odd questions are ``positive'' while all the even questions are ``negative'' in nature. In order to make them work together, we convert the points as follows: 
\[
    f_{i} = 
\begin{cases}
    5 - Q_{i}, & \text{when i is even}\\
    Q_{i} - 1, & \text{when i is odd}
\end{cases}
\]
Where \(Q_{i} \) is the answer to question numbered i. The total point is then: 
\[ 2.5 * \displaystyle \sum_{i=1}^{10} f_{i} \]
The score lies in the range 0-100. A high score means that the system is easy to use and liked by the users, while a low score means that it should be improved before publishing.

\subsection{Testing}
Users tested both versions of the game in order to compare them. First we explain to them the basics of a text-adventure: there is a description of the room you are in, you type or say simple commands in natural language in order to do things and sometimes must interact with your surroundings in order to progress. 

The user gets to play one of the game-versions and upon completion they will answer a short form that will be expanded upon in the following section: “System Usability Scale”(SECTION x.y). We record various data, such as amount of commands, completion time and if there were anything specific that the user failed on multiple times. The last check is in case we require the users to say a certain word or phrase at one part but the game has a hard time parsing the command for each user. This is done in an attempt to filter out bad programming and game design on our part.

After the user played one version and filled in the questionnaire the user then played the other version and filled in the questionnaire again but with regard to the new control scheme. We repeated this test with multiple users and we alternated between which game version was to be played first.